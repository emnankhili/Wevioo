{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf593ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Traitement de : CV AHMED DIOUF DIRIEH DIBAD AVRIL 2024 VF.docx\n",
      "‚úÖ R√©sultats enregistr√©s dans resultats_cv_test.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "import spacy\n",
    "import spacy.cli\n",
    "import importlib\n",
    "\n",
    "# === V√©rifie et charge le mod√®le spaCy ===\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_lg\")\n",
    "except OSError:\n",
    "    print(\"üîÅ Mod√®le 'fr_core_news_lg' non trouv√©. T√©l√©chargement...\")\n",
    "    spacy.cli.download(\"fr_core_news_lg\")\n",
    "    importlib.invalidate_caches()\n",
    "    nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL = \"llama3\"\n",
    "INPUT_JSON = \"result.json\"\n",
    "OUTPUT_CSV = \"resultats_cv_test.csv\"\n",
    "\n",
    "# === Fonctions utilitaires ===\n",
    "def ask_ollama(prompt):\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur Ollama : {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_name(nom_complet):\n",
    "    if not nom_complet:\n",
    "        return \"\"\n",
    "    nom_complet = re.sub(r\"\\b(dr|mr|mme|mrs|m)\\b[\\.]?\", \"\", nom_complet, flags=re.IGNORECASE)\n",
    "    return re.sub(r\"\\s+\", \" \", nom_complet.strip())\n",
    "\n",
    "def estimate_years_experience(from_year, to_year=2025):\n",
    "    try:\n",
    "        return max(0, int(to_year) - int(from_year))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def chunk_text(text, max_chars=2000):\n",
    "    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "\n",
    "def extract_from_chunk(chunk):\n",
    "    prompt = f\"\"\"\n",
    "Voici un extrait de CV :\n",
    "\n",
    "====================\n",
    "{chunk}\n",
    "====================\n",
    "\n",
    "Retourne uniquement ce JSON strict :\n",
    "{{\n",
    "  \"nom_complet\": \"\",\n",
    "  \"domaine_expertise\": \"\",\n",
    "  \"date_diplome_principal\": \"\",\n",
    "  \"annees_experience\": 0\n",
    "}}\n",
    "\n",
    "‚ö†Ô∏è Si une information est absente dans ce chunk, laisse-la vide ou √† 0. Aucune explication.\n",
    "\"\"\"\n",
    "    response = ask_ollama(prompt)\n",
    "    cleaned_response = re.sub(r\"//.*\", \"\", response)\n",
    "    try:\n",
    "        json_match = re.search(r'\\{[\\s\\S]*?\\}', cleaned_response)\n",
    "        data = json.loads(json_match.group()) if json_match else {}\n",
    "        if \"date_diplome_principal\" in data and data[\"date_diplome_principal\"]:\n",
    "            year_match = re.search(r\"\\b(19|20)\\d{2}\\b\", data[\"date_diplome_principal\"])\n",
    "            if year_match:\n",
    "                year = year_match.group()\n",
    "                data[\"date_diplome_principal\"] = year\n",
    "                data[\"annees_experience\"] = estimate_years_experience(year)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur parsing chunk JSON : {e}\")\n",
    "        print(f\"üîé Chunk brut :\\n{response}\")\n",
    "        return {}\n",
    "\n",
    "def extract_full_name(text):\n",
    "    doc = nlp(text)\n",
    "    persons = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PER\"]\n",
    "    if not persons:\n",
    "        return \"\"\n",
    "    return clean_name(\" \".join(persons[:2]))  # max deux entit√©s\n",
    "\n",
    "def extract_domain(text):\n",
    "    match = re.search(r\"(expert|sp√©cialiste|consultant|responsable) en ([^\\n\\.\\:]+)\", text, re.IGNORECASE)\n",
    "    return match.group(2).strip() if match else \"\"\n",
    "\n",
    "def find_earliest_diploma_year(text):\n",
    "    match_section = re.search(r\"5\\. *Dipl[o√¥]mes *:(.*?)(6\\. *Connaissances linguistiques *:|7\\. *Affiliation|$)\",\n",
    "                              text, re.DOTALL | re.IGNORECASE)\n",
    "    if not match_section:\n",
    "        return None\n",
    "    diplomas_text = match_section.group(1)\n",
    "\n",
    "    # Cherche les ann√©es suivies OU pr√©c√©d√©es de mots-cl√©s\n",
    "    pattern = r\"(\\b(19|20)\\d{2}\\b).{0,50}(doctorat|mast[√®e]re|licence|ing[√©e]nieur|master)|\" \\\n",
    "              r\"(doctorat|mast[√®e]re|licence|ing[√©e]nieur|master).{0,50}(\\b(19|20)\\d{2}\\b)\"\n",
    "\n",
    "    years = []\n",
    "    for match in re.finditer(pattern, diplomas_text, re.IGNORECASE):\n",
    "        for group in match.groups():\n",
    "            if group and re.match(r\"\\b(19|20)\\d{2}\\b\", group):\n",
    "                years.append(int(group))\n",
    "    return min(years) if years else None\n",
    "\n",
    "def merge_infos(chunks_data, original_text):\n",
    "    final = {\n",
    "        \"nom_complet\": \"\",\n",
    "        \"domaine_expertise\": \"\",\n",
    "        \"date_diplome_principal\": \"\",\n",
    "        \"annees_experience\": 0\n",
    "    }\n",
    "\n",
    "    for data in chunks_data:\n",
    "        for key in final:\n",
    "            if key not in (\"date_diplome_principal\", \"annees_experience\") and not final[key] and data.get(key):\n",
    "                final[key] = data[key]\n",
    "\n",
    "    if not final[\"nom_complet\"]:\n",
    "        final[\"nom_complet\"] = extract_full_name(original_text)\n",
    "\n",
    "    if not final[\"domaine_expertise\"]:\n",
    "        final[\"domaine_expertise\"] = extract_domain(original_text)\n",
    "\n",
    "    earliest_year = find_earliest_diploma_year(original_text)\n",
    "    if earliest_year:\n",
    "        final[\"date_diplome_principal\"] = str(earliest_year)\n",
    "        final[\"annees_experience\"] = estimate_years_experience(earliest_year)\n",
    "    else:\n",
    "        final[\"annees_experience\"] = estimate_years_experience(final.get(\"date_diplome_principal\", 0))\n",
    "\n",
    "    final[\"nom_complet\"] = clean_name(final[\"nom_complet\"])\n",
    "    return final\n",
    "\n",
    "def save_to_csv(data_list, path):\n",
    "    if not data_list:\n",
    "        print(\"‚ö†Ô∏è Aucun r√©sultat √† sauvegarder.\")\n",
    "        return\n",
    "    fieldnames = [\"nom_complet\", \"domaine_expertise\", \"date_diplome_principal\", \"annees_experience\", \"fichier\"]\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_list)\n",
    "    print(f\"‚úÖ R√©sultats enregistr√©s dans {path}\")\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    with open(INPUT_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        docs = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for doc in docs[:1]:  # traiter tous les CV si besoin\n",
    "        print(f\"üîç Traitement de : {doc['filename']}\")\n",
    "        text = doc[\"text\"]\n",
    "        chunks = chunk_text(text)\n",
    "        extracted_chunks = [extract_from_chunk(c) for c in chunks]\n",
    "        merged = merge_infos(extracted_chunks, text)\n",
    "        merged[\"fichier\"] = doc[\"filename\"]\n",
    "        results.append(merged)\n",
    "\n",
    "    save_to_csv(results, OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abcb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Traitement de : CV AHMED DIOUF DIRIEH DIBAD AVRIL 2024 VF.docx\n",
      "üîç Traitement de : CV Anis JENHANI_EU_fr_Expert SIG.pdf\n",
      "üîç Traitement de : CV FR BM Ahmed Faresse_Consultant international Mars25.docx\n",
      "üîç Traitement de : CV Habib BEN ALI .docx\n",
      "üîç Traitement de : CV HmidaKarboul_V2.docx\n",
      "‚úÖ R√©sultats enregistr√©s dans resultats_cv_test.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "Expert en strat√©gie d‚Äôaffaires et projets de transformation\n",
    "num√©rique\n",
    "Name Dr Ahmed-Diouf DIRIEH DIBAD\n",
    "Nationalit√©/R√©sidence Djiboutien, Republic of Djibouti\n",
    "Autre nationalit√© Canadien\n",
    "1. Nom de Famille : DIRIEH DIBAD\n",
    "2. Pr√©noms : AHMED DIOUF\n",
    "3. Date de naissance 28 septembre 1981\n",
    "4. Nationalit√© : Djiboutienne\n",
    "5. Dipl√¥mes :\n",
    "Institution Dipl√¥me\n",
    "2012 Doctorat en informatique, universit√© de Rouen, France\n",
    "2005 Master 2 en Syst√®me d‚ÄôInformation & R√©seaux, universit√© de\n",
    "Tours, France\n",
    "6. Connaissances linguistiques : Indiquer vos connaissances sur une √©chelle de 1 √† 5 (1 - excellent ; 5 -\n",
    "rudimentaire)\n",
    "Langue Lu Parl√© Ecrit\n",
    "Fran√ßais Bilingue Bilingue Bilingue\n",
    "Anglais Fonctionnel Fonctionnel Fonctionnel\n",
    "\"\"\"\n",
    "\n",
    "def find_earliest_diploma_year(text):\n",
    "    # Extraire section Dipl√¥mes (m√™me code)\n",
    "    match_section = re.search(r\"5\\. *Dipl[o√¥]mes *:(.*?)(6\\. *Connaissances linguistiques *:|7\\. *Affiliation|$)\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if not match_section:\n",
    "        print(\"‚ö†Ô∏è Section dipl√¥mes non trouv√©e.\")\n",
    "        return None\n",
    "    diplomas_text = match_section.group(1)\n",
    "    print(f\"--- Section dipl√¥mes ---\\n{diplomas_text}\\n--- Fin section dipl√¥mes ---\")\n",
    "\n",
    "    # Regex : chercher ann√©e suivie de mot-cl√© dipl√¥me dans un rayon de 50 caract√®res\n",
    "    diplome_keywords = r\"(doctorat|mast[√®e]re|licence|ing[√©e]nieur|master)\"\n",
    "    pattern = rf\"(\\b(19|20)\\d{{2}}\\b).{{0,50}}{diplome_keywords}\"\n",
    "    years = []\n",
    "    for match in re.finditer(pattern, diplomas_text, re.IGNORECASE):\n",
    "        year = match.group(1)\n",
    "        print(f\"Ann√©e trouv√©e dans dipl√¥mes : {year}\")\n",
    "        try:\n",
    "            y = int(year)\n",
    "            years.append(y)\n",
    "        except:\n",
    "            pass\n",
    "    if years:\n",
    "        print(f\"Ann√©es trouv√©es : {years}, ann√©e la plus ancienne : {min(years)}\")\n",
    "        return min(years)\n",
    "    print(\"‚ö†Ô∏è Aucune ann√©e valide trouv√©e dans dipl√¥mes.\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11db7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\3IA3\\iaenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "import requests\n",
    "import spacy\n",
    "import spacy.cli\n",
    "import importlib\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from docx2pdf import convert\n",
    "from flask import Flask, request, render_template, send_from_directory\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "# === Initialisation ===\n",
    "app = Flask(__name__)\n",
    "UPLOAD_FOLDER = \"uploads\"\n",
    "TEMP_FOLDER = \"temp\"\n",
    "RESULT_CSV = \"resultats_cv_web.csv\"\n",
    "ALLOWED_EXTENSIONS = {\"pdf\", \"docx\"}\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "os.makedirs(TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "# === spaCy init ===\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_lg\")\n",
    "except OSError:\n",
    "    spacy.cli.download(\"fr_core_news_lg\")\n",
    "    importlib.invalidate_caches()\n",
    "    nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "# === Utilitaires ===\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def convert_docx_to_pdf(docx_path, output_dir):\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        convert(docx_path, output_dir)\n",
    "        pdf_name = os.path.splitext(os.path.basename(docx_path))[0] + \".pdf\"\n",
    "        return os.path.join(output_dir, pdf_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de conversion : {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    extracted_text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text and len(text.strip()) > 20:\n",
    "                    extracted_text += text + \"\\n\"\n",
    "                else:\n",
    "                    image = page.to_image(resolution=300).original\n",
    "                    ocr_text = pytesseract.image_to_string(image, lang='eng+fra')\n",
    "                    extracted_text += ocr_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur PDF {pdf_path} : {e}\")\n",
    "    return extracted_text.strip() or None\n",
    "\n",
    "def clean_name(nom_complet):\n",
    "    nom_complet = re.sub(r\"\\b(dr|mr|mme|mrs|m)\\b[\\.]?\", \"\", nom_complet, flags=re.IGNORECASE)\n",
    "    return re.sub(r\"\\s+\", \" \", nom_complet.strip())\n",
    "\n",
    "def estimate_years_experience(from_year, to_year=2025):\n",
    "    try:\n",
    "        return max(0, int(to_year) - int(from_year))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def extract_full_name(text):\n",
    "    doc = nlp(text)\n",
    "    persons = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PER\"]\n",
    "    return clean_name(\" \".join(persons[:2])) if persons else \"\"\n",
    "\n",
    "def extract_domain(text):\n",
    "    match = re.search(r\"(expert|sp[√©e]cialiste|consultant|responsable) en ([^\\n\\.:]+)\", text, re.IGNORECASE)\n",
    "    return match.group(2).strip() if match else \"\"\n",
    "\n",
    "def find_earliest_year(text):\n",
    "    years = [int(y) for y in re.findall(r\"\\b(19|20)\\d{2}\\b\", text)]\n",
    "    return min(years) if years else None\n",
    "\n",
    "def extract_cv_info(text):\n",
    "    return {\n",
    "        \"nom_complet\": extract_full_name(text),\n",
    "        \"domaine_expertise\": extract_domain(text),\n",
    "        \"date_diplome_principal\": str(find_earliest_year(text) or \"\"),\n",
    "        \"annees_experience\": estimate_years_experience(find_earliest_year(text)),\n",
    "    }\n",
    "\n",
    "def save_to_csv(data_list, csv_file):\n",
    "    file_exists = os.path.isfile(csv_file)\n",
    "    with open(csv_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        fieldnames = [\"nom_complet\", \"domaine_expertise\", \"date_diplome_principal\", \"annees_experience\", \"fichier\"]\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(data_list)\n",
    "\n",
    "# === Routes Flask ===\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def upload():\n",
    "    if request.method == \"POST\":\n",
    "        file = request.files.get(\"cv\")\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            filepath = os.path.join(UPLOAD_FOLDER, filename)\n",
    "            file.save(filepath)\n",
    "\n",
    "            if filename.lower().endswith(\".docx\"):\n",
    "                pdf_path = convert_docx_to_pdf(filepath, TEMP_FOLDER)\n",
    "            else:\n",
    "                pdf_path = filepath\n",
    "\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            if text:\n",
    "                data = extract_cv_info(text)\n",
    "                data[\"fichier\"] = f\"<a href='/cv/{filename}' target='_blank'>{filename}</a>\"\n",
    "                save_to_csv([data], RESULT_CSV)\n",
    "                return render_template(\"result.html\", info=data)\n",
    "            return \"Erreur d'extraction du texte.\"\n",
    "    return render_template(\"upload.html\")\n",
    "\n",
    "@app.route(\"/cv/<path:filename>\")\n",
    "def serve_cv(filename):\n",
    "    return send_from_directory(UPLOAD_FOLDER, filename)\n",
    "\n",
    "# === Lancer le serveur ===\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdc278a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\3ia3\\iaenv\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: pytesseract in c:\\3ia3\\iaenv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in c:\\3ia3\\iaenv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: python-docx in c:\\3ia3\\iaenv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: docx2pdf in c:\\3ia3\\iaenv\\lib\\site-packages (0.1.8)\n",
      "Collecting flask\n",
      "  Using cached flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\3ia3\\iaenv\\lib\\site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\3ia3\\iaenv\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\3ia3\\iaenv\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\3ia3\\iaenv\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (44.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\3ia3\\iaenv\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\3ia3\\iaenv\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\3ia3\\iaenv\\lib\\site-packages (from python-docx) (4.13.2)\n",
      "Requirement already satisfied: pywin32>=227 in c:\\3ia3\\iaenv\\lib\\site-packages (from docx2pdf) (308)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\3ia3\\iaenv\\lib\\site-packages (from docx2pdf) (4.67.1)\n",
      "Collecting blinker>=1.9.0 (from flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\3ia3\\iaenv\\lib\\site-packages (from flask) (8.1.7)\n",
      "Collecting itsdangerous>=2.2.0 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\3ia3\\iaenv\\lib\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\3ia3\\iaenv\\lib\\site-packages (from flask) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from flask)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\3ia3\\iaenv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\3ia3\\iaenv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\3ia3\\iaenv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
      "Using cached flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, itsdangerous, blinker, flask\n",
      "Successfully installed blinker-1.9.0 flask-3.1.1 itsdangerous-2.2.0 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber pytesseract pillow python-docx docx2pdf flask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
